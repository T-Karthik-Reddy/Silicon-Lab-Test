config.py -
import os

# Paths
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
ROOT_DIR = os.path.dirname(os.path.dirname(BASE_DIR))
DATASET_DIR = os.path.join(ROOT_DIR, 'Dataset')
PROCESSED_DIR = os.path.join(ROOT_DIR, 'processed_dataset')
MODEL_DIR = os.path.join(BASE_DIR, 'models')
LOG_DIR = os.path.join(BASE_DIR, 'logs')

# Audio processing
SAMPLE_RATE = 16000
N_MELS = 64
N_FFT = 512
HOP_LENGTH = 320
MAX_TIME_FRAMES = 128  # Fixed for this architecture

# Data augmentation
USE_AUGMENTATION = True
TIME_MASK_PARAM = 30
FREQ_MASK_PARAM = 8
NUM_MASKS = 2

# Model
NUM_CLASSES = 2
MAX_PARAMS = 17000  # Parameter budget

# Transformer architecture - optimized to use ~15K of 17K budget
D_MODEL = 28  # Increased from 20 for better capacity
NUM_HEADS = 4  # 4 heads with 7 dims each (28/4=7)
NUM_LAYERS = 2
DROPOUT = 0.1

# Training - UPDATED
BATCH_SIZE = 32  # Reduced for better gradient estimates
LEARNING_RATE = 3e-4  # Lower learning rate for transformers
NUM_EPOCHS = 100
PATIENCE = 20  # Increased patience
WEIGHT_DECAY = 1e-5  # Reduced weight decay
GRAD_CLIP = 1.0  # Gradient clipping

# Learning rate scheduling
USE_COSINE_SCHEDULE = False  # Use ReduceLROnPlateau for transformers
LR_FACTOR = 0.5
LR_PATIENCE = 6

# Data split
TRAIN_SPLIT = 0.7
VAL_SPLIT = 0.15
TEST_SPLIT = 0.15

# Class weights for imbalanced data
USE_CLASS_WEIGHTS = True

CLASS_NAMES = ['cry', 'not_cry']


Model.py -
import tensorflow as tf
import numpy as np
import math

class PositionalEncoding(tf.keras.layers.Layer):
    def __init__(self, d_model, max_len=512, dropout=0.1):
        super().__init__()
        self.dropout = tf.keras.layers.Dropout(dropout)
        self.d_model = d_model
        self.max_len = max_len

        # Create positional encoding
        pe = np.zeros((max_len, d_model))
        position = np.arange(0, max_len)[:, np.newaxis]
        div_term = np.exp(np.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))
        
        pe[:, 0::2] = np.sin(position * div_term)
        pe[:, 1::2] = np.cos(position * div_term)
        
        # Shape (1, max_len, d_model)
        self.pe = tf.constant(pe[np.newaxis, ...], dtype=tf.float32)

    def call(self, x, training=False):
        """
        Args:
            x: Tensor of shape (batch_size, seq_len, d_model)
        """
        # Slice pe to the current sequence length
        seq_len = tf.shape(x)[1]
        x = x + self.pe[:, :seq_len, :]
        return self.dropout(x, training=training)

class TransformerEncoderLayer(tf.keras.layers.Layer):
    """
    Replicates torch.nn.TransformerEncoderLayer with batch_first=True, norm_first=False
    """
    def __init__(self, d_model, nhead, dim_feedforward, dropout=0.1, activation='relu'):
        super().__init__()
        self.self_attn = tf.keras.layers.MultiHeadAttention(num_heads=nhead, key_dim=d_model // nhead)
        
        self.linear1 = tf.keras.layers.Dense(dim_feedforward, activation=activation)
        self.dropout = tf.keras.layers.Dropout(dropout)
        self.linear2 = tf.keras.layers.Dense(d_model)
        
        self.norm1 = tf.keras.layers.LayerNormalization(epsilon=1e-5)
        self.norm2 = tf.keras.layers.LayerNormalization(epsilon=1e-5)
        
        self.dropout1 = tf.keras.layers.Dropout(dropout)
        self.dropout2 = tf.keras.layers.Dropout(dropout)

    def call(self, src, training=False):
        # Self Attention
        # Post-LN: x = norm(x + sublayer(x))
        src2 = self.self_attn(src, src, return_attention_scores=False)
        src = src + self.dropout1(src2, training=training)
        src = self.norm1(src)
        
        # Feed Forward
        src2 = self.linear2(self.dropout(self.linear1(src), training=training))
        src = src + self.dropout2(src2, training=training)
        src = self.norm2(src)
        return src

class TransformerClassifier(tf.keras.Model):
    def __init__(self, num_classes=2, d_model=28, num_heads=4, num_layers=2, dropout=0.2):
        super().__init__()
        
        self.d_model = d_model
        
        # Input projection: (B, 1, 64, T) -> (B, T, 64) -> (B, T, d_model)
        self.input_proj = tf.keras.layers.Dense(d_model, use_bias=False)
        self.input_norm = tf.keras.layers.LayerNormalization(epsilon=1e-5)
        
        # Positional encoding
        self.pos_encoding = PositionalEncoding(d_model, max_len=512, dropout=dropout)
        
        # Transformer encoder layers
        self.enc_layers = [
            TransformerEncoderLayer(
                d_model=d_model,
                nhead=num_heads,
                dim_feedforward=d_model * 2,
                dropout=dropout,
                activation='relu'
            ) for _ in range(num_layers)
        ]
        
        # Simple classifier head
        self.classifier_head = tf.keras.Sequential([
            tf.keras.layers.Dropout(dropout),
            tf.keras.layers.Dense(num_classes)
        ])
        
    def call(self, x, training=False):
        """
        Args:
            x: Input tensor of shape (B, 1, 64, T)
        Returns:
            Output tensor of shape (B, num_classes)
        """
        # Reshape: (B, 1, 64, T) -> (B, 64, T)
        x = tf.squeeze(x, axis=1)
        # Permute: (B, 64, T) -> (B, T, 64)
        x = tf.transpose(x, perm=[0, 2, 1])
        
        # Project to d_model: (B, T, 64) -> (B, T, d_model)
        x = self.input_proj(x)
        x = self.input_norm(x)
        
        # Add positional encoding
        x = self.pos_encoding(x, training=training)
        
        # Transformer encoding
        for layer in self.enc_layers:
            x = layer(x, training=training)
        
        # Global mean pooling over time: (B, T, d_model) -> (B, d_model)
        x = tf.reduce_mean(x, axis=1)
        
        # Classifier: (B, d_model) -> (B, num_classes)
        x = self.classifier_head(x, training=training)
        
        return x

def count_parameters(model):
    """Count trainable parameters"""
    # Note: Model must be built (called once) before counting
    return model.count_params()

def test_model_initialization():
    """Test that model produces different outputs for different inputs"""
    model = TransformerClassifier()
    
    # Create two different random inputs
    x1 = tf.random.normal((1, 1, 64, 128))
    x2 = tf.random.normal((1, 1, 64, 128))
    
    # Call once to build
    out1 = model(x1, training=False)
    out2 = model(x2, training=False)
    
    # Check if outputs are different
    diff = tf.reduce_max(tf.abs(out1 - out2))
    if diff < 1e-5:
        print("❌ ERROR: Model outputs are identical!")
        return False
    else:
        print("✓ Model produces different outputs for different inputs")
        print(f" Output 1: {out1.numpy()}")
        print(f" Output 2: {out2.numpy()}")
        print(f" Difference: {diff.numpy():.6f}")
        return True

if __name__ == '__main__':
    # Optimized configuration
    TEST_D_MODEL = 28
    TEST_NUM_HEADS = 4
    TEST_NUM_LAYERS = 2
    TEST_DROPOUT = 0.2
    TEST_NUM_CLASSES = 2
    TEST_MAX_PARAMS = 17000
    
    model = TransformerClassifier(
        num_classes=TEST_NUM_CLASSES,
        d_model=TEST_D_MODEL,
        num_heads=TEST_NUM_HEADS,
        num_layers=TEST_NUM_LAYERS,
        dropout=TEST_DROPOUT
    )
    
    # Build the model with a dummy input
    dummy = tf.random.normal((1, 1, 64, 128))
    _ = model(dummy)
    
    params = count_parameters(model)
    print(f'Total parameters: {params:,}')
    print(f'Parameter budget: {TEST_MAX_PARAMS:,}')
    
    if params <= TEST_MAX_PARAMS:
        print(f'✓ Within budget! ({TEST_MAX_PARAMS - params:,} parameters remaining)')
    else:
        print(f'❌ Exceeds budget by {params - TEST_MAX_PARAMS:,} parameters')
    
    # Test forward pass with fixed length
    print('\n--- Testing Fixed Length Input ---')
    x_fixed = tf.random.normal((2, 1, 64, 128))
    out = model(x_fixed)
    print(f'Input shape: {x_fixed.shape}')
    print(f'Output shape: {out.shape}')
    
    # Test forward pass with variable length
    print('\n--- Testing Variable Length Input ---')
    x_var = tf.random.normal((2, 1, 64, 200))
    out_var = model(x_var)
    print(f'Input shape: {x_var.shape}')
    print(f'Output shape: {out_var.shape}')
    
    # Test initialization
    print('\n--- Testing Model Initialization ---')
    test_model_initialization()
    
    # Check that different batches produce different outputs
    print("\n--- Testing Batch Outputs ---")
    out = model(x_fixed, training=False)
    print(f"Batch output 0: {out[0].numpy()}")
    print(f"Batch output 1: {out[1].numpy()}")
    
    is_diff = not np.allclose(out[0], out[1], atol=1e-5)
    print(f"Outputs are different: {is_diff}")



train.py -

import os
import sys
import tensorflow as tf
import numpy as np
from tqdm import tqdm
from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, confusion_matrix
from datetime import datetime

# Add parent directory to path
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(__file__))))

from dataset import get_dataloaders, load_data
import config
from Model import TransformerClassifier, count_parameters

class Logger:
    def __init__(self, filename):
        self.terminal = sys.stdout
        self.log = open(filename, 'w')
    
    def write(self, message):
        self.terminal.write(message)
        self.log.write(message)
        self.log.flush()
    
    def flush(self):
        self.terminal.flush()
        self.log.flush()
        
    def close(self):
        self.log.close()

def get_lr(optimizer):
    if isinstance(optimizer.learning_rate, tf.keras.optimizers.schedules.LearningRateSchedule):
        return optimizer.learning_rate(optimizer.iterations).numpy()
    return float(optimizer.learning_rate.numpy())

@tf.function
def train_step(model, inputs, labels, criterion, optimizer, grad_clip=None):
    with tf.GradientTape() as tape:
        outputs = model(inputs, training=True)
        loss = criterion(labels, outputs)
    
    gradients = tape.gradient(loss, model.trainable_variables)
    
    if grad_clip:
        gradients, _ = tf.clip_by_global_norm(gradients, grad_clip)
        
    optimizer.apply_gradients(zip(gradients, model.trainable_variables))
    return loss, outputs

def train_epoch(model, loader, criterion, optimizer, epoch):
    total_loss = 0.0
    all_preds, all_labels = [], []
    num_batches = 0
    
    # Get gradient clip value if it exists
    grad_clip = getattr(config, 'GRAD_CLIP', None)
    
    pbar = tqdm(loader, desc=f'Epoch {epoch} Train', ncols=100, leave=False)
    for inputs, labels in pbar:
        loss, outputs = train_step(model, inputs, labels, criterion, optimizer, grad_clip)
        
        total_loss += loss.numpy()
        num_batches += 1
        
        preds = tf.argmax(outputs, axis=1).numpy()
        all_preds.extend(preds)
        all_labels.extend(labels.numpy())
        
        pbar.set_postfix({'loss': f'{loss.numpy():.4f}'})
    
    avg_loss = total_loss / num_batches if num_batches > 0 else 0
    accuracy = accuracy_score(all_labels, all_preds)
    f1 = f1_score(all_labels, all_preds, average='macro', zero_division=0)
    cm = confusion_matrix(all_labels, all_preds)
    
    return avg_loss, accuracy, f1, cm

def validate(model, loader, criterion):
    total_loss = 0.0
    all_preds, all_labels, all_probs = [], [], []
    num_batches = 0
    
    pbar = tqdm(loader, desc='Validation', ncols=100, leave=False)
    for inputs, labels in pbar:
        outputs = model(inputs, training=False)
        loss = criterion(labels, outputs)
        
        total_loss += loss.numpy()
        num_batches += 1
        
        probs = tf.nn.softmax(outputs, axis=1).numpy()
        preds = tf.argmax(outputs, axis=1).numpy()
        
        all_preds.extend(preds)
        all_labels.extend(labels.numpy())
        all_probs.extend(probs)
    
    avg_loss = total_loss / num_batches if num_batches > 0 else 0
    accuracy = accuracy_score(all_labels, all_preds)
    f1 = f1_score(all_labels, all_preds, average='macro', zero_division=0)
    
    # ROC-AUC
    if config.NUM_CLASSES == 2:
        all_probs = np.array(all_probs)[:, 1]
        try:
            auc = roc_auc_score(all_labels, all_probs)
        except:
            auc = 0.0
    else:
        auc = 0.0
        
    cm = confusion_matrix(all_labels, all_preds)
    
    return avg_loss, accuracy, f1, auc, cm

def main():
    # Create directories
    os.makedirs(config.MODEL_DIR, exist_ok=True)
    os.makedirs(config.LOG_DIR, exist_ok=True)
    
    # Setup logging
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    log_file = os.path.join(config.LOG_DIR, f'training_log_{timestamp}.txt')
    logger = Logger(log_file)
    sys.stdout = logger
    
    # Device check
    gpus = tf.config.list_physical_devices('GPU')
    device_name = 'GPU' if gpus else 'CPU'
    
    print(f'='*60)
    print(f'Training Started: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}')
    print(f'='*60)
    print(f'Architecture: Transformer-based Classifier (TensorFlow)')
    print(f'Using device: {device_name}')
    
    # Load data and create loaders
    train_loader, val_loader, test_loader, stats = get_dataloaders()
    
    # Get sizes (approximate based on generator length)
    train_gen, _, _, _ = load_data()
    train_size = len(train_gen)
    
    # Calculate class weights
    # To replicate PyTorch WeightedRandomSampler or Loss weights, we can compute standard weights
    # Note: TF CrossEntropyLoss takes 'sample_weight' or we can pass 'class_weight' to model.fit
    # Here we implement weighted loss in the criterion manually or via class_weight argument in loss if available
    
    # Replicating the label counting from original script
    train_labels = train_gen.labels
    unique, counts = np.unique(train_labels, return_counts=True)
    print(f'\nClass distribution:')
    for cls, count in zip(unique, counts):
        print(f' Class {cls} ({config.CLASS_NAMES[cls]}): {count} samples ({count/len(train_labels)*100:.1f}%)')
        
    class_weights = None
    if hasattr(config, 'USE_CLASS_WEIGHTS') and config.USE_CLASS_WEIGHTS:
        # Calculate weights: n_samples / (n_classes * n_samples_j)
        weights = len(train_labels) / (len(unique) * counts)
        class_weights = {i: w for i, w in zip(unique, weights)}
        print(f'Class weights: {class_weights}')
        
        # In TF, we usually pass class weights to model.fit. 
        # Since we use custom loop, we will wrap the loss function to handle weights
        # or use sample_weight during training.
    
    # Save stats
    np.save(os.path.join(config.MODEL_DIR, 'stats.npy'), stats)
    print(f'\nSaved normalization stats - Mean: {stats["mean"]:.4f}, Std: {stats["std"]:.4f}')
    
    # Initialize model
    model = TransformerClassifier(
        num_classes=config.NUM_CLASSES,
        d_model=config.D_MODEL,
        num_heads=config.NUM_HEADS,
        num_layers=config.NUM_LAYERS,
        dropout=config.DROPOUT
    )
    
    # Build model with dummy input to initialize weights and count params
    dummy_input = tf.zeros((1, 1, 64, 128))
    model(dummy_input)
    
    total_params = count_parameters(model)
    print(f'\nModel parameters: {total_params:,}')
    
    if hasattr(config, 'MAX_PARAMS'):
        if total_params > config.MAX_PARAMS:
            print(f'WARNING: Model has {total_params:,} parameters, exceeds limit of {config.MAX_PARAMS:,}')
        else:
            print(f'✓ Within parameter budget ({config.MAX_PARAMS - total_params:,} remaining)')
            
    # Loss and Optimizer
    # TF CrossEntropyFromLogits=True is equivalent to PyTorch CrossEntropyLoss (which includes Softmax)
    loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)
    
    def criterion(y_true, y_pred):
        if class_weights is not None:
            # Apply class weights manually
            weight_vector = tf.gather(list(class_weights.values()), y_true)
            loss = loss_object(y_true, y_pred, sample_weight=weight_vector)
        else:
            loss = loss_object(y_true, y_pred)
        return loss

    # Scheduler and Optimizer
    # TF doesn't have an exact equivalent of ReduceLROnPlateau that works purely as an object
    # inside a custom loop easily without Callbacks, so we manually manage LR.
    current_lr = config.LEARNING_RATE
    optimizer = tf.keras.optimizers.AdamW(
        learning_rate=current_lr, 
        weight_decay=config.WEIGHT_DECAY
    )
    
    # Training loop
    best_f1 = 0
    best_acc = 0
    patience_counter = 0
    
    print(f'\n{"="*60}')
    print('Starting Training Loop')
    print(f'{"="*60}')
    
    for epoch in range(config.NUM_EPOCHS):
        print(f'\n{"="*60}')
        print(f'Epoch {epoch+1}/{config.NUM_EPOCHS}')
        print(f'{"="*60}')
        
        # Train
        train_loss, train_acc, train_f1, train_cm = train_epoch(
            model, train_loader, criterion, optimizer, epoch+1
        )
        
        # Validate
        val_loss, val_acc, val_f1, val_auc, val_cm = validate(
            model, val_loader, criterion
        )
        
        # Learning Rate Scheduling (ReduceLROnPlateau logic manually)
        # If using Cosine, use tf.keras.optimizers.schedules.CosineDecay
        if hasattr(config, 'USE_COSINE_SCHEDULE') and config.USE_COSINE_SCHEDULE:
            # Note: True cosine schedule updates every step, simpler here to leave fixed or implement specifically
            pass 
        else:
            # Simple ReduceLROnPlateau logic
            # PyTorch default uses mode='max' for F1/Acc, factor=0.1, patience=10
            # Here assuming logic based on config
            pass # Implementation omitted for brevity, keeping current_lr fixed or relying on manual update logic
            
        print(f'\nTrain - Loss: {train_loss:.4f} | Acc: {train_acc:.4f} | F1: {train_f1:.4f}')
        print(f'Train Confusion Matrix:\n{train_cm}')
        print(f'\nVal  - Loss: {val_loss:.4f} | Acc: {val_acc:.4f} | F1: {val_f1:.4f} | AUC: {val_auc:.4f}')
        print(f'Val Confusion Matrix:\n{val_cm}')
        print(f'LR: {get_lr(optimizer):.6f}')
        
        # Save best model
        if val_f1 > best_f1:
            best_f1 = val_f1
            best_acc = val_acc
            patience_counter = 0
            
            # Save model weights
            model.save_weights(os.path.join(config.MODEL_DIR, 'best_model.weights.h5'))
            
            # Save metadata
            meta_data = {
                'epoch': epoch,
                'val_f1': val_f1,
                'val_acc': val_acc,
                'val_auc': val_auc,
                'stats': stats
            }
            np.save(os.path.join(config.MODEL_DIR, 'meta_data.npy'), meta_data)
            print(f'✓ Saved best model with F1: {best_f1:.4f}, Acc: {best_acc:.4f}')
        else:
            patience_counter += 1
            print(f'Patience: {patience_counter}/{config.PATIENCE}')
            
            # Manual LR reduction on plateau logic (simplified)
            if patience_counter == config.LR_PATIENCE:
                old_lr = float(optimizer.learning_rate.numpy())
                new_lr = old_lr * config.LR_FACTOR
                optimizer.learning_rate.assign(new_lr)
                print(f"Reducing learning rate to {new_lr}")
        
        # Early stopping
        if patience_counter >= config.PATIENCE:
            print(f'\nEarly stopping triggered after {epoch+1} epochs')
            break
            
    # Test evaluation
    print(f'\n{"="*60}')
    print('Testing Best Model')
    print(f'{"="*60}')
    
    try:
        model.load_weights(os.path.join(config.MODEL_DIR, 'best_model.weights.h5'))
    except Exception as e:
        print(f"Error loading weights: {e}")
        
    test_loss, test_acc, test_f1, test_auc, test_cm = validate(
        model, test_loader, criterion
    )
    
    print(f'\nFinal Test Results:')
    print(f' Loss:   {test_loss:.4f}')
    print(f' Accuracy: {test_acc:.4f} ({test_acc*100:.2f}%)')
    print(f' F1 Score: {test_f1:.4f}')
    print(f' AUC:    {test_auc:.4f}')
    print(f'\nTest Confusion Matrix:')
    print(test_cm)
    
    # Per-class metrics
    print(f'\nPer-Class Test Metrics:')
    if test_cm.shape[0] == 2:
        cry_precision = test_cm[0][0] / (test_cm[0][0] + test_cm[1][0]) if (test_cm[0][0] + test_cm[1][0]) > 0 else 0
        cry_recall = test_cm[0][0] / (test_cm[0][0] + test_cm[0][1]) if (test_cm[0][0] + test_cm[0][1]) > 0 else 0
        not_cry_precision = test_cm[1][1] / (test_cm[0][1] + test_cm[1][1]) if (test_cm[0][1] + test_cm[1][1]) > 0 else 0
        not_cry_recall = test_cm[1][1] / (test_cm[1][0] + test_cm[1][1]) if (test_cm[1][0] + test_cm[1][1]) > 0 else 0
        
        print(f' Cry class:')
        print(f'  Precision: {cry_precision:.4f}')
        print(f'  Recall:  {cry_recall:.4f}')
        print(f' Not Cry class:')
        print(f'  Precision: {not_cry_precision:.4f}')
        print(f'  Recall:  {not_cry_recall:.4f}')

    print(f'\n{"="*60}')
    print(f'Training Completed: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}')
    print(f'Best Val F1: {best_f1:.4f}, Best Val Acc: {best_acc:.4f}')
    print(f'Log saved to: {log_file}')
    print(f'{"="*60}')
    
    logger.close()
    sys.stdout = sys.stdout.terminal

if __name__ == '__main__':
    main()


inference.py -
import os
import sys
import tensorflow as tf
import numpy as np
from tqdm import tqdm
from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, confusion_matrix
from datetime import datetime

# Add parent directory to path
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(__file__))))

from dataset import get_dataloaders, load_data
import config
from Model import TransformerClassifier, count_parameters

class Logger:
    def __init__(self, filename):
        self.terminal = sys.stdout
        self.log = open(filename, 'w')
    
    def write(self, message):
        self.terminal.write(message)
        self.log.write(message)
        self.log.flush()
    
    def flush(self):
        self.terminal.flush()
        self.log.flush()
        
    def close(self):
        self.log.close()

def get_lr(optimizer):
    if isinstance(optimizer.learning_rate, tf.keras.optimizers.schedules.LearningRateSchedule):
        return optimizer.learning_rate(optimizer.iterations).numpy()
    return float(optimizer.learning_rate.numpy())

@tf.function
def train_step(model, inputs, labels, criterion, optimizer, grad_clip=None):
    with tf.GradientTape() as tape:
        outputs = model(inputs, training=True)
        loss = criterion(labels, outputs)
    
    gradients = tape.gradient(loss, model.trainable_variables)
    
    if grad_clip:
        gradients, _ = tf.clip_by_global_norm(gradients, grad_clip)
        
    optimizer.apply_gradients(zip(gradients, model.trainable_variables))
    return loss, outputs

def train_epoch(model, loader, criterion, optimizer, epoch):
    total_loss = 0.0
    all_preds, all_labels = [], []
    num_batches = 0
    
    # Get gradient clip value if it exists
    grad_clip = getattr(config, 'GRAD_CLIP', None)
    
    pbar = tqdm(loader, desc=f'Epoch {epoch} Train', ncols=100, leave=False)
    for inputs, labels in pbar:
        loss, outputs = train_step(model, inputs, labels, criterion, optimizer, grad_clip)
        
        total_loss += loss.numpy()
        num_batches += 1
        
        preds = tf.argmax(outputs, axis=1).numpy()
        all_preds.extend(preds)
        all_labels.extend(labels.numpy())
        
        pbar.set_postfix({'loss': f'{loss.numpy():.4f}'})
    
    avg_loss = total_loss / num_batches if num_batches > 0 else 0
    accuracy = accuracy_score(all_labels, all_preds)
    f1 = f1_score(all_labels, all_preds, average='macro', zero_division=0)
    cm = confusion_matrix(all_labels, all_preds)
    
    return avg_loss, accuracy, f1, cm

def validate(model, loader, criterion):
    total_loss = 0.0
    all_preds, all_labels, all_probs = [], [], []
    num_batches = 0
    
    pbar = tqdm(loader, desc='Validation', ncols=100, leave=False)
    for inputs, labels in pbar:
        outputs = model(inputs, training=False)
        loss = criterion(labels, outputs)
        
        total_loss += loss.numpy()
        num_batches += 1
        
        probs = tf.nn.softmax(outputs, axis=1).numpy()
        preds = tf.argmax(outputs, axis=1).numpy()
        
        all_preds.extend(preds)
        all_labels.extend(labels.numpy())
        all_probs.extend(probs)
    
    avg_loss = total_loss / num_batches if num_batches > 0 else 0
    accuracy = accuracy_score(all_labels, all_preds)
    f1 = f1_score(all_labels, all_preds, average='macro', zero_division=0)
    
    # ROC-AUC
    if config.NUM_CLASSES == 2:
        all_probs = np.array(all_probs)[:, 1]
        try:
            auc = roc_auc_score(all_labels, all_probs)
        except:
            auc = 0.0
    else:
        auc = 0.0
        
    cm = confusion_matrix(all_labels, all_preds)
    
    return avg_loss, accuracy, f1, auc, cm

def main():
    # Create directories
    os.makedirs(config.MODEL_DIR, exist_ok=True)
    os.makedirs(config.LOG_DIR, exist_ok=True)
    
    # Setup logging
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    log_file = os.path.join(config.LOG_DIR, f'training_log_{timestamp}.txt')
    logger = Logger(log_file)
    sys.stdout = logger
    
    # Device check
    gpus = tf.config.list_physical_devices('GPU')
    device_name = 'GPU' if gpus else 'CPU'
    
    print(f'='*60)
    print(f'Training Started: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}')
    print(f'='*60)
    print(f'Architecture: Transformer-based Classifier (TensorFlow)')
    print(f'Using device: {device_name}')
    
    # Load data and create loaders
    train_loader, val_loader, test_loader, stats = get_dataloaders()
    
    # Get sizes (approximate based on generator length)
    train_gen, _, _, _ = load_data()
    train_size = len(train_gen)
    
    # Calculate class weights
    # To replicate PyTorch WeightedRandomSampler or Loss weights, we can compute standard weights
    # Note: TF CrossEntropyLoss takes 'sample_weight' or we can pass 'class_weight' to model.fit
    # Here we implement weighted loss in the criterion manually or via class_weight argument in loss if available
    
    # Replicating the label counting from original script
    train_labels = train_gen.labels
    unique, counts = np.unique(train_labels, return_counts=True)
    print(f'\nClass distribution:')
    for cls, count in zip(unique, counts):
        print(f' Class {cls} ({config.CLASS_NAMES[cls]}): {count} samples ({count/len(train_labels)*100:.1f}%)')
        
    class_weights = None
    if hasattr(config, 'USE_CLASS_WEIGHTS') and config.USE_CLASS_WEIGHTS:
        # Calculate weights: n_samples / (n_classes * n_samples_j)
        weights = len(train_labels) / (len(unique) * counts)
        class_weights = {i: w for i, w in zip(unique, weights)}
        print(f'Class weights: {class_weights}')
        
        # In TF, we usually pass class weights to model.fit. 
        # Since we use custom loop, we will wrap the loss function to handle weights
        # or use sample_weight during training.
    
    # Save stats
    np.save(os.path.join(config.MODEL_DIR, 'stats.npy'), stats)
    print(f'\nSaved normalization stats - Mean: {stats["mean"]:.4f}, Std: {stats["std"]:.4f}')
    
    # Initialize model
    model = TransformerClassifier(
        num_classes=config.NUM_CLASSES,
        d_model=config.D_MODEL,
        num_heads=config.NUM_HEADS,
        num_layers=config.NUM_LAYERS,
        dropout=config.DROPOUT
    )
    
    # Build model with dummy input to initialize weights and count params
    dummy_input = tf.zeros((1, 1, 64, 128))
    model(dummy_input)
    
    total_params = count_parameters(model)
    print(f'\nModel parameters: {total_params:,}')
    
    if hasattr(config, 'MAX_PARAMS'):
        if total_params > config.MAX_PARAMS:
            print(f'WARNING: Model has {total_params:,} parameters, exceeds limit of {config.MAX_PARAMS:,}')
        else:
            print(f'✓ Within parameter budget ({config.MAX_PARAMS - total_params:,} remaining)')
            
    # Loss and Optimizer
    # TF CrossEntropyFromLogits=True is equivalent to PyTorch CrossEntropyLoss (which includes Softmax)
    loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)
    
    def criterion(y_true, y_pred):
        if class_weights is not None:
            # Apply class weights manually
            weight_vector = tf.gather(list(class_weights.values()), y_true)
            loss = loss_object(y_true, y_pred, sample_weight=weight_vector)
        else:
            loss = loss_object(y_true, y_pred)
        return loss

    # Scheduler and Optimizer
    # TF doesn't have an exact equivalent of ReduceLROnPlateau that works purely as an object
    # inside a custom loop easily without Callbacks, so we manually manage LR.
    current_lr = config.LEARNING_RATE
    optimizer = tf.keras.optimizers.AdamW(
        learning_rate=current_lr, 
        weight_decay=config.WEIGHT_DECAY
    )
    
    # Training loop
    best_f1 = 0
    best_acc = 0
    patience_counter = 0
    
    print(f'\n{"="*60}')
    print('Starting Training Loop')
    print(f'{"="*60}')
    
    for epoch in range(config.NUM_EPOCHS):
        print(f'\n{"="*60}')
        print(f'Epoch {epoch+1}/{config.NUM_EPOCHS}')
        print(f'{"="*60}')
        
        # Train
        train_loss, train_acc, train_f1, train_cm = train_epoch(
            model, train_loader, criterion, optimizer, epoch+1
        )
        
        # Validate
        val_loss, val_acc, val_f1, val_auc, val_cm = validate(
            model, val_loader, criterion
        )
        
        # Learning Rate Scheduling (ReduceLROnPlateau logic manually)
        # If using Cosine, use tf.keras.optimizers.schedules.CosineDecay
        if hasattr(config, 'USE_COSINE_SCHEDULE') and config.USE_COSINE_SCHEDULE:
            # Note: True cosine schedule updates every step, simpler here to leave fixed or implement specifically
            pass 
        else:
            # Simple ReduceLROnPlateau logic
            # PyTorch default uses mode='max' for F1/Acc, factor=0.1, patience=10
            # Here assuming logic based on config
            pass # Implementation omitted for brevity, keeping current_lr fixed or relying on manual update logic
            
        print(f'\nTrain - Loss: {train_loss:.4f} | Acc: {train_acc:.4f} | F1: {train_f1:.4f}')
        print(f'Train Confusion Matrix:\n{train_cm}')
        print(f'\nVal  - Loss: {val_loss:.4f} | Acc: {val_acc:.4f} | F1: {val_f1:.4f} | AUC: {val_auc:.4f}')
        print(f'Val Confusion Matrix:\n{val_cm}')
        print(f'LR: {get_lr(optimizer):.6f}')
        
        # Save best model
        if val_f1 > best_f1:
            best_f1 = val_f1
            best_acc = val_acc
            patience_counter = 0
            
            # Save model weights
            model.save_weights(os.path.join(config.MODEL_DIR, 'best_model.weights.h5'))
            
            # Save metadata
            meta_data = {
                'epoch': epoch,
                'val_f1': val_f1,
                'val_acc': val_acc,
                'val_auc': val_auc,
                'stats': stats
            }
            np.save(os.path.join(config.MODEL_DIR, 'meta_data.npy'), meta_data)
            print(f'✓ Saved best model with F1: {best_f1:.4f}, Acc: {best_acc:.4f}')
        else:
            patience_counter += 1
            print(f'Patience: {patience_counter}/{config.PATIENCE}')
            
            # Manual LR reduction on plateau logic (simplified)
            if patience_counter == config.LR_PATIENCE:
                old_lr = float(optimizer.learning_rate.numpy())
                new_lr = old_lr * config.LR_FACTOR
                optimizer.learning_rate.assign(new_lr)
                print(f"Reducing learning rate to {new_lr}")
        
        # Early stopping
        if patience_counter >= config.PATIENCE:
            print(f'\nEarly stopping triggered after {epoch+1} epochs')
            break
            
    # Test evaluation
    print(f'\n{"="*60}')
    print('Testing Best Model')
    print(f'{"="*60}')
    
    try:
        model.load_weights(os.path.join(config.MODEL_DIR, 'best_model.weights.h5'))
    except Exception as e:
        print(f"Error loading weights: {e}")
        
    test_loss, test_acc, test_f1, test_auc, test_cm = validate(
        model, test_loader, criterion
    )
    
    print(f'\nFinal Test Results:')
    print(f' Loss:   {test_loss:.4f}')
    print(f' Accuracy: {test_acc:.4f} ({test_acc*100:.2f}%)')
    print(f' F1 Score: {test_f1:.4f}')
    print(f' AUC:    {test_auc:.4f}')
    print(f'\nTest Confusion Matrix:')
    print(test_cm)
    
    # Per-class metrics
    print(f'\nPer-Class Test Metrics:')
    if test_cm.shape[0] == 2:
        cry_precision = test_cm[0][0] / (test_cm[0][0] + test_cm[1][0]) if (test_cm[0][0] + test_cm[1][0]) > 0 else 0
        cry_recall = test_cm[0][0] / (test_cm[0][0] + test_cm[0][1]) if (test_cm[0][0] + test_cm[0][1]) > 0 else 0
        not_cry_precision = test_cm[1][1] / (test_cm[0][1] + test_cm[1][1]) if (test_cm[0][1] + test_cm[1][1]) > 0 else 0
        not_cry_recall = test_cm[1][1] / (test_cm[1][0] + test_cm[1][1]) if (test_cm[1][0] + test_cm[1][1]) > 0 else 0
        
        print(f' Cry class:')
        print(f'  Precision: {cry_precision:.4f}')
        print(f'  Recall:  {cry_recall:.4f}')
        print(f' Not Cry class:')
        print(f'  Precision: {not_cry_precision:.4f}')
        print(f'  Recall:  {not_cry_recall:.4f}')

    print(f'\n{"="*60}')
    print(f'Training Completed: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}')
    print(f'Best Val F1: {best_f1:.4f}, Best Val Acc: {best_acc:.4f}')
    print(f'Log saved to: {log_file}')
    print(f'{"="*60}')
    
    logger.close()
    sys.stdout = sys.stdout.terminal

if __name__ == '__main__':
    main()


preprocess.py -

import os
import librosa
import numpy as np
import matplotlib.pyplot as plt
from pathlib import Path
from tqdm import tqdm
import config

def load_and_preprocess_audio(audio_path, sr=config.SAMPLE_RATE):
    """Load audio with preprocessing"""
    # Load audio
    y, _ = librosa.load(audio_path, sr=sr, mono=True)
    
    # Remove silence from beginning and end
    y, _ = librosa.effects.trim(y, top_db=20)
    
    # Normalize audio to [-1, 1] range
    if np.abs(y).max() > 0:
        y = y / np.abs(y).max()
    
    return y

def extract_melspectrogram(audio_path, sr=config.SAMPLE_RATE, n_mels=config.N_MELS):
    """Extract mel-spectrogram from audio file with improved settings"""
    y = load_and_preprocess_audio(audio_path, sr)
    
    # Extract mel-spectrogram
    mel_spec = librosa.feature.melspectrogram(
        y=y, 
        sr=sr, 
        n_mels=n_mels, 
        n_fft=config.N_FFT, 
        hop_length=config.HOP_LENGTH,
        fmin=50,  # Focus on relevant frequency range for baby cries
        fmax=8000,  # Most baby cry energy is below 8kHz
        power=2.0  # Use power spectrogram (squared magnitude)
    )
    
    # Convert to dB scale with better reference
    mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max, top_db=80)
    
    return mel_spec_db, len(y) / sr

def pad_or_truncate(mel_spec, max_frames=config.MAX_TIME_FRAMES):
    """Pad or truncate to fixed length with edge padding"""
    current_frames = mel_spec.shape[1]
    
    if current_frames < max_frames:
        # Use edge padding instead of zero padding
        pad_width = max_frames - current_frames
        mel_spec = np.pad(mel_spec, ((0, 0), (0, pad_width)), mode='edge')
    else:
        # Take center crop if too long
        start = (current_frames - max_frames) // 2
        mel_spec = mel_spec[:, start:start + max_frames]
    
    return mel_spec

def save_melspectrogram(mel_spec, output_path):
    """Save mel-spectrogram as numpy array"""
    np.save(output_path, mel_spec)

def visualize_sample(mel_spec, title, output_path):
    """Visualize a mel-spectrogram sample"""
    plt.figure(figsize=(10, 4))
    librosa.display.specshow(mel_spec, sr=config.SAMPLE_RATE, 
                            hop_length=config.HOP_LENGTH,
                            x_axis='time', y_axis='mel')
    plt.colorbar(format='%+2.0f dB')
    plt.title(title)
    plt.tight_layout()
    plt.savefig(output_path, dpi=100, bbox_inches='tight')
    plt.close()

def analyze_dataset_stats():
    """Analyze dataset statistics before processing"""
    print("="*60)
    print("Dataset Analysis")
    print("="*60)
    
    for class_name in config.CLASS_NAMES:
        input_dir = os.path.join(config.DATASET_DIR, class_name)
        audio_files = list(Path(input_dir).glob('*.wav')) + list(Path(input_dir).glob('*.ogg'))
        
        if not audio_files:
            print(f"\nWARNING: No audio files found in {input_dir}")
            continue
        
        durations = []
        sample_rates = []
        
        print(f"\n{class_name.upper()} class:")
        print(f"  Total files: {len(audio_files)}")
        
        # Sample a few files for analysis
        for audio_file in audio_files[:min(10, len(audio_files))]:
            try:
                y, sr = librosa.load(str(audio_file), sr=None)
                duration = len(y) / sr
                durations.append(duration)
                sample_rates.append(sr)
            except Exception as e:
                print(f"  Error reading {audio_file.name}: {e}")
        
        if durations:
            print(f"  Sample durations (seconds):")
            print(f"    Min: {min(durations):.2f}, Max: {max(durations):.2f}, Mean: {np.mean(durations):.2f}")
            print(f"  Original sample rates: {set(sample_rates)}")
            
            # Calculate expected frames
            expected_frames = np.array(durations) * config.SAMPLE_RATE / config.HOP_LENGTH
            print(f"  Expected mel-spec frames: {expected_frames.mean():.0f} (target: {config.MAX_TIME_FRAMES})")

def process_dataset():
    """Process all audio files and save mel-spectrograms"""
    
    # First analyze the dataset
    analyze_dataset_stats()
    
    print("\n" + "="*60)
    print("Starting Processing")
    print("="*60)
    
    os.makedirs(config.PROCESSED_DIR, exist_ok=True)
    
    # Create visualization directory
    viz_dir = os.path.join(config.PROCESSED_DIR, 'visualizations')
    os.makedirs(viz_dir, exist_ok=True)
    
    all_stats = {'total': 0, 'errors': 0, 'warnings': 0}
    
    for class_name in config.CLASS_NAMES:
        input_dir = os.path.join(config.DATASET_DIR, class_name)
        output_dir = os.path.join(config.PROCESSED_DIR, class_name)
        os.makedirs(output_dir, exist_ok=True)
        
        audio_files = list(Path(input_dir).glob('*.wav')) + list(Path(input_dir).glob('*.ogg'))
        print(f'\nProcessing {class_name}: {len(audio_files)} files')
        
        class_stats = {'processed': 0, 'errors': 0, 'short': 0, 'long': 0}
        
        for i, audio_file in enumerate(tqdm(audio_files, desc=f'{class_name}', ncols=100)):
            try:
                mel_spec, duration = extract_melspectrogram(str(audio_file))
                
                # Check duration warnings
                if duration < 3.0:
                    class_stats['short'] += 1
                elif duration > 10.0:
                    class_stats['long'] += 1
                
                mel_spec = pad_or_truncate(mel_spec)
                
                output_path = os.path.join(output_dir, audio_file.stem + '.npy')
                save_melspectrogram(mel_spec, output_path)
                
                # Save visualization for first 3 samples of each class
                if i < 3:
                    viz_path = os.path.join(viz_dir, f'{class_name}_{i}.png')
                    visualize_sample(mel_spec, f'{class_name} - {audio_file.name}', viz_path)
                
                class_stats['processed'] += 1
                all_stats['total'] += 1
                
            except Exception as e:
                print(f'\nError processing {audio_file}: {e}')
                class_stats['errors'] += 1
                all_stats['errors'] += 1
        
        # Print class statistics
        print(f'\n{class_name} Statistics:')
        print(f'  Successfully processed: {class_stats["processed"]}')
        print(f'  Errors: {class_stats["errors"]}')
        print(f'  Short files (<3s): {class_stats["short"]}')
        print(f'  Long files (>10s): {class_stats["long"]}')
    
    print(f'\n{"="*60}')
    print('Processing Complete!')
    print(f'{"="*60}')
    print(f'Total files processed: {all_stats["total"]}')
    print(f'Total errors: {all_stats["errors"]}')
    print(f'Saved to: {config.PROCESSED_DIR}')
    print(f'Visualizations saved to: {viz_dir}')
    print(f'\nNext step: Run train.py to train the model')

if __name__ == '__main__':
    process_dataset()